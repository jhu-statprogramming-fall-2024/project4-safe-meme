{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets Notes on Range/Resolution**\n",
    "\n",
    "1. Daymet v4 (Meterologic Data)\n",
    "    * North America\n",
    "    * 1980.01.01 to 2023.12.31\n",
    "    * 1000m x 1000m, Daily\n",
    "    * EEID: NASA/ORNL/DAYMET_V4\n",
    "\n",
    "2. MODIS (Terra 1km) - EVI/NDVI\n",
    "    * Global\n",
    "    * 2000.02.18 to 2024.10.31\n",
    "    * 1000m x 1000m, 16-day Composite\n",
    "    * EEID: MODIS/061/MOD13A2\n",
    "\n",
    "3. MODIS (Terra 500m) - ET/LE\n",
    "    * Global\n",
    "    * 2000.01.01 to 2023.12.27\n",
    "    * 500m x 500m, 8-Day composite\n",
    "    * MODIS/061/MOD16A2GF\n",
    "\n",
    "4. MODIS (Terra 500m) - Leaf Area and FPAR\n",
    "    * Global\n",
    "    * 2000.02.18 to 2024.11.08\n",
    "    * 500m x 500m, 8-Day composite\n",
    "    * MODIS/061/MOD15A2H\n",
    "\n",
    "5. Global Food-Support Analysis Data (GFSAD) Cropland\n",
    "    * Global\n",
    "    * 2010.01.01\n",
    "    * 1000m x 1000m, one-time (2010)\n",
    "    * EEID: USGS/GFSAD1000_V1\n",
    "\n",
    "---\n",
    "**Types of Vegetation Metrics**\n",
    "\n",
    "- **Evapotranspiration (ET):** Measures the total water loss from soil and plants; higher ET indicates active plant growth and sufficient water availability. Over 25 years, an overall decrease in ET due to climate change could indicate reduced plant activity or increased water stress.\n",
    "\n",
    "- **Fraction of Photosynthetically Active Radiation (FPAR):** Represents the fraction of sunlight absorbed by vegetation for photosynthesis; higher FPAR denotes healthier, more productive crops. Over 25 years, a declining FPAR trend could indicate an overall reduction in crop canopy density.\n",
    "\n",
    "- **Leaf Area Index (LAI):** Quantifies the total leaf area per unit ground area; higher LAI reflects denser foliage and robust plant growth. Over 25 years, an overall decrease in LAI over time could point to diminished vegetation cover or stunted growth.\n",
    "\n",
    "- **Enhanced Vegetation Index (EVI):** An index that enhances vegetation signals by reducing atmospheric and soil background noise; higher EVI values correspond to healthier vegetation. Over 25 years, a downward trend in EVI might indicate declining vegetation vigor.\n",
    "\n",
    "- **Normalized Difference Vegetation Index (NDVI):** Assesses vegetation greenness by comparing red and near-infrared reflectance; higher NDVI values signify healthier, greener vegetation. Over 25 years, a decrease in NDVI over 25 years could suggest reduced vegetation health or coverage.\n",
    "\n",
    "**NDVI and EVI** capture vegetation greenness and vigor, offering a direct assessment of plant health, whereas **LAI**, **FPAR**, and **ET** provide information on structural and functional aspects of vegetation. The scientific basis for preferring NDVI/EVI lies in their sensitivity to chlorophyll content and ability to detect changes in vegetation health more directly. The general hypothesis is: if the climate in 2000 was more favorable for crops than in 2024, we would expect to see higher values of ET, FPAR, LAI, EVI, and NDVI in 2000, reflecting more vigorous plant growth, denser foliage, and healthier vegetation due to optimal growing conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_0JLhFqfSY1uiEaW?source=Init\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import folium\n",
    "\n",
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an image file from GEE, count pixels in full image\n",
    "def pixel_count(map_img, scale=None, geometry=None):\n",
    "\n",
    "  # Set the default geometry to cover the entire image;\n",
    "  # otherwise, use supplied geometry\n",
    "  if geometry is None:\n",
    "    geometry = map_img.geometry()\n",
    "\n",
    "  # Set default scale to the image's native scale;\n",
    "  # otherwise, use supplied scale\n",
    "  if scale is None:\n",
    "      scale = map_img.projection().nominalScale().getInfo()\n",
    "\n",
    "  count = map_img.reduceRegion(\n",
    "    reducer=ee.Reducer.count(),   # Aggregation function: Counts non-masked pixels\n",
    "    geometry=geometry,            # Region of interest (default or user-supplied)\n",
    "    scale=scale,                  # Spatial resolution for the operation \n",
    "    maxPixels=1e13                # Maximum number of pixels to process\n",
    "  ).getInfo()\n",
    "\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STANDARD PARAMETERS #######\n",
    "# Define ROI (contiguous United States)\n",
    "roi = ee.Geometry.Rectangle([-125, 24, -65, 50])\n",
    "\n",
    "# Define time range\n",
    "start_date = '2000-02-18'\n",
    "end_date = '2023-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DAYMETv4 weekly images: 1246\n",
      "['system:time_start', 'week', 'system:index', 'system:bands', 'system:band_names']\n",
      "['dayl', 'prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp']\n",
      "1\n",
      "Spatial resolution of the weekly image: 1000 meters\n",
      "CRS: EPSG:3347\n",
      "Weekly Dates: ['2023-12-15', '2023-12-22', '2023-12-29']\n"
     ]
    }
   ],
   "source": [
    "# Get date from image\n",
    "def get_date(image):\n",
    "  return ee.Image(image).date().format('YYYY-MM-dd')\n",
    "\n",
    "# Base function for applying North America-centric projection specification to a specifc img instance\n",
    "def set_std_NA_projection(daymet_img):\n",
    "\n",
    "    # Define the DAYMET projection using ee.Projection: NAD83 / Canada Lambert (EPSG:3347)\n",
    "    NA_projection = ee.Projection('EPSG:3347') \n",
    "\n",
    "    return daymet_img.reproject(\n",
    "        crs=NA_projection,\n",
    "        scale=daymet_img.projection().nominalScale()    # Use Daymet's native resolution\n",
    "    )\n",
    "\n",
    "# Define a function to calculate weekly averages\n",
    "def weekly_average_daymet(date, daily_collection, start_date='2000-02-18'):\n",
    "    start = ee.Date(date)\n",
    "    end = start.advance(1, 'week')\n",
    "    filtered_collection = daily_collection.filterDate(start, end)\n",
    "    mean_image = filtered_collection.mean()\n",
    "\n",
    "    original_crs = daily_collection.first().projection().crs()\n",
    "    original_scale = daily_collection.first().projection().nominalScale()\n",
    "    mean_image = mean_image.setDefaultProjection(crs=original_crs, scale=original_scale)\n",
    "\n",
    "    # Calculate week number since the start date\n",
    "    week_number = start.difference(ee.Date(start_date), 'week').add(1)\n",
    "    \n",
    "    mean_image = mean_image.set('system:time_start', start.millis())\n",
    "    mean_image = mean_image.set('week', week_number)\n",
    "\n",
    "    return mean_image\n",
    "\n",
    "### DAYMETv4 pre-processing\n",
    "# Load and filter Daymet data; set default projection\n",
    "daymet_daily = ee.ImageCollection('NASA/ORNL/DAYMET_V4') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(roi)\n",
    "daymet_daily = daymet_daily.map(set_std_NA_projection)\n",
    "\n",
    "average_map = lambda date:  weekly_average_daymet(date, daily_collection=daymet_daily)\n",
    "\n",
    "# Create a list of starting dates for each week\n",
    "start_dates = ee.List.sequence(\n",
    "    ee.Date(start_date).millis(),\n",
    "    ee.Date(end_date).millis(),\n",
    "    7 * 24 * 60 * 60 * 1000  # 7 days in milliseconds\n",
    ")\n",
    "\n",
    "# Map the weekly_average function over the list of start dates\n",
    "weekly_averages = start_dates.map(average_map)\n",
    "\n",
    "# Convert the list of weekly averages to an ImageCollection\n",
    "daymet_weekly = ee.ImageCollection(weekly_averages)\n",
    "daymet_weekly = daymet_weekly.map(set_std_NA_projection)\n",
    "\n",
    "# Status Check\n",
    "print('Number of DAYMETv4 weekly images:', daymet_weekly.size().getInfo())\n",
    "print(daymet_weekly.first().propertyNames().getInfo())\n",
    "print(daymet_weekly.first().bandNames().getInfo())\n",
    "print(daymet_weekly.first().get('week').getInfo())\n",
    "print(f\"Spatial resolution of the weekly image: {daymet_weekly.first().projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {daymet_weekly.first().projection().crs().getInfo()}\")\n",
    "\n",
    "# Print the list of dates\n",
    "weekly_dates_list = daymet_weekly.toList(daymet_weekly.size()).map(get_date)\n",
    "print('Weekly Dates:', weekly_dates_list.getInfo()[-3:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_interpolation(img_collection, start_date, end_date):\n",
    "  \"\"\"Interpolates an ImageCollection to weekly averages.\"\"\"\n",
    "\n",
    "  # Create a list of weekly start dates\n",
    "  weekly_dates = ee.List.sequence(\n",
    "      ee.Date(start_date).millis(),  # Use .millis() directly\n",
    "      ee.Date(end_date).millis(),    # Use .millis() directly\n",
    "      7 * 24 * 60 * 60 * 1000        # 7 days in milliseconds\n",
    "  )\n",
    "\n",
    "  # Function to compute weekly average\n",
    "  def weekly_average(date_millis):\n",
    "    date = ee.Date(date_millis)\n",
    "    start = date.advance(-8, 'day')  # 8 days before\n",
    "    end = date.advance(8, 'day')     # 8 days after\n",
    "\n",
    "    # use 17-day window to ensure at least one data point is captured, avoiding null bands \n",
    "    filtered = img_collection.filterDate(start, end)\n",
    "\n",
    "    original_crs = img_collection.first().projection().crs()\n",
    "    original_scale = img_collection.first().projection().nominalScale()\n",
    "\n",
    "    weekly_avg = filtered.mean().set('system:time_start', date_millis)\n",
    "    weekly_avg = weekly_avg.setDefaultProjection(crs=original_crs, scale=original_scale)\n",
    "\n",
    "    return weekly_avg\n",
    "\n",
    "  # Map the weekly average function over the date list\n",
    "  weekly_evi = weekly_dates.map(weekly_average)\n",
    "\n",
    "  return ee.ImageCollection(weekly_evi)\n",
    "\n",
    "### MODIS EVI\n",
    "# Load and filter MODIS-EVI data\n",
    "modis_EVI = ee.ImageCollection('MODIS/061/MOD13A2') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(roi) \\\n",
    "    .select(['EVI', 'NDVI'])\n",
    "\n",
    "# Interpolate data to produce weekly images\n",
    "weekly_EVI = weekly_interpolation(modis_EVI, start_date, end_date)\n",
    "\n",
    "# Reproject to 1000m x 1000m while keeping the original projection\n",
    "weekly_EVI = weekly_EVI.map(lambda image: image.reproject(\n",
    "    crs=image.projection(),  # Maintain the original projection\n",
    "    scale=1000               # 1km resolution\n",
    "))\n",
    "\n",
    "### Status Check\n",
    "print('Number of Weekly MODIS-EVI images:', weekly_EVI.size().getInfo())\n",
    "print(weekly_EVI.first().bandNames().getInfo())\n",
    "print(f\"Spatial resolution of weekly_EVI image: {weekly_EVI.first().projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {weekly_EVI.first().projection().crs().getInfo()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIS ET (500m)\n",
    "# Load and filter MODIS-ET data\n",
    "modis_ET = ee.ImageCollection('MODIS/061/MOD16A2GF') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(roi) \\\n",
    "    .select(['ET', 'LE', 'PET', 'PLE'])\n",
    "\n",
    "# Downsample MODIS ET to 1km\n",
    "modis_ET = modis_ET.map(lambda image: image.reduceResolution(\n",
    "    reducer=ee.Reducer.mean(),\n",
    "    maxPixels=1024  # This is important to avoid exceeding memory limits\n",
    ").reproject(\n",
    "    crs=image.projection(),  # Maintain the original projection\n",
    "    scale=1000               # 1km resolution\n",
    "))\n",
    "\n",
    "# Interpolate data to produce weekly images\n",
    "weekly_ET = weekly_interpolation(modis_ET, start_date, end_date)\n",
    "\n",
    "### MODIS FPAR (500m)\n",
    "# Load and filter MODIS-FPAR data\n",
    "modis_FPAR = ee.ImageCollection('MODIS/061/MOD15A2H') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(roi) \\\n",
    "    .select(['Fpar_500m', 'Lai_500m'],  # Old band names\n",
    "            ['FPAR', 'LAI'],            # New band names\n",
    "    )\n",
    "\n",
    "# Downsample MODIS FPAR to 1km\n",
    "modis_FPAR = modis_FPAR.map(lambda image: image.reduceResolution(\n",
    "    reducer=ee.Reducer.mean(),\n",
    "    maxPixels=1024\n",
    ").reproject(\n",
    "    crs=image.projection(),\n",
    "    scale=1000\n",
    "))\n",
    "\n",
    "# Interpolate data to produce weekly images\n",
    "weekly_FPAR = weekly_interpolation(modis_FPAR, start_date, end_date)\n",
    "\n",
    "##### status check\n",
    "print('Number of Weekly MODIS-ET images:', weekly_EVI.size().getInfo())\n",
    "print(weekly_ET.first().bandNames().getInfo())\n",
    "print(f\"Spatial resolution of the image: {weekly_ET.first().projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {weekly_ET.first().projection().crs().getInfo()}\")\n",
    "print()\n",
    "\n",
    "print('Number of Weekly MODIS-FPAR images:', weekly_EVI.size().getInfo())\n",
    "print(weekly_FPAR.first().bandNames().getInfo())\n",
    "print(f\"Spatial resolution of the image: {weekly_FPAR.first().projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {weekly_FPAR.first().projection().crs().getInfo()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GFSAD\n",
    "# Define a function to reclassify the land cover values to:\n",
    "# (0) no crops\n",
    "# (1) irrigated crops\n",
    "# (2) rainfed crops\n",
    "def reclassify_gfsad_landcover(image):\n",
    "  # Create a dictionary mapping old values to new values\n",
    "  remap_values = {\n",
    "      0: 0,  # Non-croplands remain 0\n",
    "      1: 1,  # Irrigation major becomes irrigated (1)\n",
    "      2: 1,  # Irrigation minor becomes irrigated (1)\n",
    "      3: 2,  # Rainfed becomes rainfed (2)\n",
    "      4: 2,  # Rainfed with minor fragments becomes rainfed (2) \n",
    "      5: 2,  # Rainfed with very minor fragments becomes rainfed (2)\n",
    "  }\n",
    "\n",
    "  # Use the remap() function to reclassify the image\n",
    "  reclassified = image.remap(\n",
    "      list(remap_values.keys()), list(remap_values.values())\n",
    "  )\n",
    "\n",
    "  reclassified = reclassified.rename(['crop'])\n",
    "\n",
    "  return reclassified\n",
    "\n",
    "# Load GFSAD data and reclassify input data\n",
    "gfsad = reclassify_gfsad_landcover(ee.Image('USGS/GFSAD1000_V1'))\n",
    "\n",
    "# status check\n",
    "print(gfsad.bandNames().getInfo())\n",
    "print(f\"Spatial resolution of the GFSAD image: {gfsad.projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS of GFSAD: {gfsad.projection().crs().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [daymet_weekly, weekly_EVI, weekly_ET, weekly_FPAR]\n",
    "limit = 1245\n",
    "limited_datasets = [col.limit(limit) for col in datasets]\n",
    "\n",
    "# Combine the limited collections\n",
    "merged_dataset = ee.ImageCollection(limited_datasets[0])\n",
    "for img_set in limited_datasets[1:]:\n",
    "  merged_dataset = merged_dataset.combine(img_set)\n",
    "\n",
    "# Add gfsad band data to all images in the merged datasets\n",
    "band_order = ['crop', 'dayl', 'prcp', 'srad', 'swe', 'tmax', 'tmin', 'vp', 'EVI', 'NDVI', 'ET', 'LE', 'PET', 'PLE', 'FPAR', 'LAI']\n",
    "add_gfsad_bands = lambda img: img.addBands(gfsad)\n",
    "reorder_bands = lambda img: img.select(band_order)\n",
    "merged_dataset = merged_dataset.map(add_gfsad_bands)\n",
    "\n",
    "# Skip week 71, reorder all bands; week 71 is missing FPAR data....\n",
    "merged_dataset = merged_dataset.filter(ee.Filter.neq('system:index', '70')).map(reorder_bands)\n",
    "\n",
    "print(merged_dataset.size().getInfo())\n",
    "print(merged_dataset.first().bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all images across all bands have consistent, common projection\n",
    "# Since focusing on CONUS, use EPSG:3347 as default\n",
    "target_projection_crs = ee.Projection('EPSG:3347') \n",
    "target_scale = 1000  # meters\n",
    "\n",
    "def reproject_image(image):\n",
    "    return image.reproject(crs=target_projection_crs, scale=target_scale)\n",
    "\n",
    "merged_dataset = merged_dataset.map(reproject_image)\n",
    "\n",
    "print(f\"Spatial resolution of merged data image: {merged_dataset.first().projection().nominalScale().getInfo()} meters\")\n",
    "print(f\"CRS: {merged_dataset.first().projection().crs().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# Load the US states FeatureCollection\n",
    "states = ee.FeatureCollection(\"TIGER/2018/States\")\n",
    "\n",
    "# Filter for Illinois\n",
    "roi = states.filter(ee.Filter.eq('NAME', 'Illinois'))\n",
    "\n",
    "# Apply preprocessing to the ImageCollection\n",
    "def process_and_export(image):\n",
    "    \n",
    "    # Preprocess the image (clip to ROI, resample, and convert bands)\n",
    "    clipped_image = image.clip(roi).toFloat().resample('bilinear')\n",
    "    \n",
    "    # Get the date from the image \n",
    "    date = ee.Date(image.get('system:time_start'))\n",
    "    date_string = date.format('YYYY-MM-dd').getInfo()\n",
    "\n",
    "    # Calculate the week number\n",
    "    start_date = ee.Date('2000-02-18') \n",
    "    week_number = date.difference(start_date, 'week').add(1).getInfo()\n",
    "\n",
    "    # Pad the week number with zeros to ensure it has four digits\n",
    "    week_string = str(week_number).zfill(4)\n",
    "\n",
    "    # Create an export task for each image\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=clipped_image,\n",
    "        description=f'california_{date_string}',\n",
    "        folder='EarthEngineExports',\n",
    "        fileNamePrefix=f'illinois_1kmx1km_{week_string}_{date_string}',\n",
    "        crs='EPSG:3347',\n",
    "        scale=1000,\n",
    "        region=roi.geometry().bounds(),\n",
    "        maxPixels=1e13,\n",
    "        fileFormat='GeoTIFF'\n",
    "    )\n",
    "    \n",
    "    task.start()\n",
    "    print(f\"Started export task for {date_string}. Task ID: {task.id}\")\n",
    "\n",
    "    return(task)\n",
    "\n",
    "# Iterate over all images in the ImageCollection\n",
    "tasks = []\n",
    "full_list = merged_dataset.toList(merged_dataset.size())\n",
    "for i in range(merged_dataset.size().getInfo()):\n",
    "    image = ee.Image(full_list.get(i))\n",
    "\n",
    "    task = process_and_export(image)\n",
    "    tasks.append((i, task))\n",
    "\n",
    "    print(task.status())\n",
    "    index = str(i + 1).zfill(4)\n",
    "    print(index)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
